{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure matplotlib styling\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'sans-serif',\n",
    "    'font.size': 12,\n",
    "    'axes.labelsize': 12,\n",
    "    'xtick.labelsize': 10,\n",
    "    'ytick.labelsize': 10,\n",
    "    'legend.fontsize': 10,\n",
    "    'lines.linewidth': 2,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup paths\n",
    "BASE_DIR = Path(\"data/eval_parallelized/\")\n",
    "BASE_DIR = Path(\"/Users/roy/data/ripple_bench/parallelized\")\n",
    "\n",
    "BASE_RESULTS = {\n",
    "    \"llama\": BASE_DIR / \"Llama-3-8b-Instruct_ripple_results.csv\",\n",
    "    \"zephyr\": BASE_DIR / \"zephyr-7b-beta_ripple_results.csv\",\n",
    "}\n",
    "\n",
    "UNLEARNING_RESULTS = {\n",
    "    \"llama\": {\n",
    "        \"elm\": BASE_DIR / \"llama-3-8b-instruct-elm-ckpt7_ripple_results.csv\",\n",
    "        \"graddiff\": BASE_DIR / \"llama-3-8b-instruct-graddiff-ckpt8_ripple_results.csv\",\n",
    "        \"pbj\": BASE_DIR / \"llama-3-8b-instruct-pbj-ckpt6_ripple_results.csv\",\n",
    "        \"repnoise\": BASE_DIR / \"llama-3-8b-instruct-repnoise-ckpt6_ripple_results.csv\",\n",
    "        \"rmu\": BASE_DIR / \"llama-3-8b-instruct-rmu-ckpt6_ripple_results.csv\",\n",
    "        \"rmu_lat\": BASE_DIR / \"llama-3-8b-instruct-rmu-lat-ckpt7_ripple_results.csv\",\n",
    "        \"rr\": BASE_DIR / \"llama-3-8b-instruct-rr-ckpt8_ripple_results.csv\",\n",
    "        \"tar\": BASE_DIR / \"llama-3-8b-instruct-tar-ckpt8_ripple_results.csv\",\n",
    "    },\n",
    "    \"zephyr\": {\n",
    "        \"elm\": BASE_DIR / \"zephyr-7b-elm_ripple_results.csv\",\n",
    "    }\n",
    "}\n",
    "\n",
    "PLOT_DIR = Path(\"plots/\")\n",
    "PLOT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Distance Distribution Analysis\n",
    "\n",
    "RAG distance represents how far a topic is from WMDP topics in the Wikipedia RAG retrieval ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load base model results to analyze RAG distances\n",
    "df_llama = pd.read_csv(BASE_RESULTS[\"llama\"])\n",
    "df_zephyr = pd.read_csv(BASE_RESULTS[\"zephyr\"])\n",
    "\n",
    "print(\"Data structure:\")\n",
    "print(f\"Columns: {df_llama.columns.tolist()}\")\n",
    "print(f\"\\nLlama data points: {len(df_llama)}\")\n",
    "print(f\"Zephyr data points: {len(df_zephyr)}\")\n",
    "print(f\"\\nDistance range (Llama): {df_llama['distance'].min()} - {df_llama['distance'].max()}\")\n",
    "print(f\"Distance range (Zephyr): {df_zephyr['distance'].min()} - {df_zephyr['distance'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze RAG distance distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Distribution of RAG distances\n",
    "ax1 = axes[0]\n",
    "ax1.hist(df_llama['distance'], bins=50, alpha=0.7, label='Llama', color='blue', edgecolor='black')\n",
    "ax1.hist(df_zephyr['distance'], bins=50, alpha=0.7, label='Zephyr', color='orange', edgecolor='black')\n",
    "ax1.set_xlabel('RAG Distance')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_title('Distribution of RAG Distances')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Cumulative distribution\n",
    "ax2 = axes[1]\n",
    "llama_distances_sorted = np.sort(df_llama['distance'])\n",
    "llama_cumulative = np.arange(1, len(llama_distances_sorted) + 1) / len(llama_distances_sorted)\n",
    "zephyr_distances_sorted = np.sort(df_zephyr['distance'])\n",
    "zephyr_cumulative = np.arange(1, len(zephyr_distances_sorted) + 1) / len(zephyr_distances_sorted)\n",
    "\n",
    "ax2.plot(llama_distances_sorted, llama_cumulative, label='Llama', linewidth=2)\n",
    "ax2.plot(zephyr_distances_sorted, zephyr_cumulative, label='Zephyr', linewidth=2)\n",
    "ax2.set_xlabel('RAG Distance')\n",
    "ax2.set_ylabel('Cumulative Proportion')\n",
    "ax2.set_title('Cumulative Distribution of RAG Distances')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_xlim(0, 100)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save plot\n",
    "date_str = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "filename = f\"rag_distance_distribution_{date_str}\"\n",
    "plt.savefig(PLOT_DIR / f\"{filename}.png\", dpi=150, bbox_inches='tight')\n",
    "plt.savefig(PLOT_DIR / f\"{filename}.pdf\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(\"\\nRAG Distance Statistics:\")\n",
    "print(f\"Llama - Mean: {df_llama['distance'].mean():.2f}, Median: {df_llama['distance'].median():.2f}, Std: {df_llama['distance'].std():.2f}\")\n",
    "print(f\"Zephyr - Mean: {df_zephyr['distance'].mean():.2f}, Median: {df_zephyr['distance'].median():.2f}, Std: {df_zephyr['distance'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Distance vs Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rag_vs_accuracy(model=\"llama\", bucket_size=10, max_distance=100):\n",
    "    \"\"\"Plot RAG distance vs accuracy for base and unlearned models.\"\"\"\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Load base model data\n",
    "    df_base = pd.read_csv(BASE_RESULTS[model])\n",
    "    df_base = df_base[df_base['distance'] < max_distance]\n",
    "    df_base['distance_bucket'] = (df_base['distance'] // bucket_size) * bucket_size\n",
    "    \n",
    "    # Calculate accuracy by distance bucket\n",
    "    base_accuracy = df_base.groupby('distance_bucket')['is_correct'].agg(['mean', 'std', 'count'])\n",
    "    base_accuracy['sem'] = base_accuracy['std'] / np.sqrt(base_accuracy['count'])\n",
    "    \n",
    "    # Plot 1: Base model accuracy vs RAG distance\n",
    "    ax1.errorbar(base_accuracy.index, base_accuracy['mean'] * 100, \n",
    "                yerr=base_accuracy['sem'] * 100,\n",
    "                marker='o', linewidth=2, markersize=8, capsize=5,\n",
    "                color='black', label=f'{model.title()} Base')\n",
    "    \n",
    "    ax1.set_xlabel('RAG Distance (bucketed)', fontsize=12)\n",
    "    ax1.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "    ax1.set_title(f'Base Model Accuracy vs RAG Distance\\n{model.title()}', fontsize=14)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend()\n",
    "    ax1.set_ylim(0, 100)\n",
    "    \n",
    "    # Plot 2: Compare base vs unlearned across RAG distances\n",
    "    METHOD_COLORS = {\n",
    "        'elm': '#FF6B6B', 'rmu': '#4ECDC4', 'graddiff': '#95E77E',\n",
    "        'pbj': '#FFD93D', 'tar': '#A8E6CF', 'rmu_lat': '#FF8B94',\n",
    "        'repnoise': '#B4A7D6', 'rr': '#FFB347'\n",
    "    }\n",
    "    \n",
    "    # Plot base again for comparison\n",
    "    ax2.errorbar(base_accuracy.index, base_accuracy['mean'] * 100,\n",
    "                yerr=base_accuracy['sem'] * 100,\n",
    "                marker='o', linewidth=3, markersize=8, capsize=5,\n",
    "                color='black', label='Base', alpha=0.9, zorder=10)\n",
    "    \n",
    "    # Plot unlearning methods\n",
    "    for method, path in UNLEARNING_RESULTS[model].items():\n",
    "        if path.exists():\n",
    "            df_unlearn = pd.read_csv(path)\n",
    "            df_unlearn = df_unlearn[df_unlearn['distance'] < max_distance]\n",
    "            df_unlearn['distance_bucket'] = (df_unlearn['distance'] // bucket_size) * bucket_size\n",
    "            \n",
    "            unlearn_accuracy = df_unlearn.groupby('distance_bucket')['is_correct'].agg(['mean', 'std', 'count'])\n",
    "            unlearn_accuracy['sem'] = unlearn_accuracy['std'] / np.sqrt(unlearn_accuracy['count'])\n",
    "            \n",
    "            color = METHOD_COLORS.get(method, '#888888')\n",
    "            ax2.errorbar(unlearn_accuracy.index, unlearn_accuracy['mean'] * 100,\n",
    "                        yerr=unlearn_accuracy['sem'] * 100,\n",
    "                        marker='s', linewidth=2, markersize=6, capsize=3,\n",
    "                        color=color, label=method.upper().replace('_', '-'), alpha=0.7)\n",
    "    \n",
    "    ax2.set_xlabel('RAG Distance (bucketed)', fontsize=12)\n",
    "    ax2.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "    ax2.set_title(f'RAG Distance vs Accuracy: All Methods\\n{model.title()}', fontsize=14)\n",
    "    ax2.legend(loc='best', ncol=2, fontsize=9)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_ylim(0, 100)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save\n",
    "    date_str = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    filename = f\"rag_distance_vs_accuracy_{model}_{date_str}\"\n",
    "    plt.savefig(PLOT_DIR / f\"{filename}.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.savefig(PLOT_DIR / f\"{filename}.pdf\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Generate plots\n",
    "plot_rag_vs_accuracy(model=\"llama\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Distance Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_rag_correlations(model=\"llama\"):\n",
    "    \"\"\"Analyze correlations between RAG distance and accuracy changes.\"\"\"\n",
    "    \n",
    "    # Load base model data\n",
    "    df_base = pd.read_csv(BASE_RESULTS[model])\n",
    "    \n",
    "    # Calculate topic-level statistics if source_topic exists\n",
    "    if 'source_topic' in df_base.columns:\n",
    "        topic_stats_base = df_base.groupby('source_topic').agg({\n",
    "            'is_correct': 'mean',\n",
    "            'distance': 'first',\n",
    "            'question': 'count'\n",
    "        }).rename(columns={'is_correct': 'base_accuracy', 'question': 'n_questions'})\n",
    "    else:\n",
    "        # Group by question if no source_topic\n",
    "        topic_stats_base = df_base.groupby('question').agg({\n",
    "            'is_correct': 'mean',\n",
    "            'distance': 'first'\n",
    "        }).rename(columns={'is_correct': 'base_accuracy'})\n",
    "        topic_stats_base['n_questions'] = 1\n",
    "    \n",
    "    # Prepare correlation results\n",
    "    correlation_results = []\n",
    "    \n",
    "    # Analyze each unlearning method\n",
    "    for method, path in UNLEARNING_RESULTS[model].items():\n",
    "        if not path.exists():\n",
    "            continue\n",
    "            \n",
    "        df_unlearn = pd.read_csv(path)\n",
    "        \n",
    "        if 'source_topic' in df_unlearn.columns:\n",
    "            topic_stats_unlearn = df_unlearn.groupby('source_topic')['is_correct'].mean()\n",
    "            topic_stats_unlearn.name = 'unlearn_accuracy'\n",
    "            \n",
    "            # Merge with base stats\n",
    "            merged_stats = topic_stats_base.join(topic_stats_unlearn, how='inner')\n",
    "        else:\n",
    "            topic_stats_unlearn = df_unlearn.groupby('question')['is_correct'].mean()\n",
    "            topic_stats_unlearn.name = 'unlearn_accuracy'\n",
    "            merged_stats = topic_stats_base.join(topic_stats_unlearn, how='inner')\n",
    "        \n",
    "        # Calculate accuracy delta\n",
    "        merged_stats['accuracy_delta'] = merged_stats['base_accuracy'] - merged_stats['unlearn_accuracy']\n",
    "        \n",
    "        # Filter for topics with reasonable base accuracy\n",
    "        filtered_stats = merged_stats[merged_stats['base_accuracy'] > 0.4]\n",
    "        \n",
    "        if len(filtered_stats) > 10:\n",
    "            # Calculate different distance metrics and their correlations\n",
    "            rag_dist = filtered_stats['distance'].values\n",
    "            acc_delta = filtered_stats['accuracy_delta'].values\n",
    "            \n",
    "            # RAG distance correlations\n",
    "            pearson_r, pearson_p = stats.pearsonr(rag_dist, acc_delta)\n",
    "            spearman_r, spearman_p = stats.spearmanr(rag_dist, acc_delta)\n",
    "            \n",
    "            # Alternative distance transformations\n",
    "            log_dist = np.log1p(rag_dist)\n",
    "            log_pearson_r, _ = stats.pearsonr(log_dist, acc_delta)\n",
    "            \n",
    "            inv_dist = 1 / (1 + rag_dist)\n",
    "            inv_pearson_r, _ = stats.pearsonr(inv_dist, acc_delta)\n",
    "            \n",
    "            exp_dist = np.exp(-rag_dist / 10)\n",
    "            exp_pearson_r, _ = stats.pearsonr(exp_dist, acc_delta)\n",
    "            \n",
    "            correlation_results.append({\n",
    "                'Method': method.upper(),\n",
    "                'RAG Pearson': pearson_r,\n",
    "                'RAG Spearman': spearman_r,\n",
    "                'Log(1+d) Pearson': log_pearson_r,\n",
    "                '1/(1+d) Pearson': inv_pearson_r,\n",
    "                'exp(-d/10) Pearson': exp_pearson_r,\n",
    "                'N Topics': len(filtered_stats)\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(correlation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze correlations for Llama\n",
    "corr_df = analyze_rag_correlations(model=\"llama\")\n",
    "\n",
    "if len(corr_df) > 0:\n",
    "    print(\"RAG Distance Correlation Analysis (Llama):\")\n",
    "    print(\"=\"*80)\n",
    "    print(corr_df.to_string(index=False))\n",
    "    \n",
    "    # Visualize correlations\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Prepare data for grouped bar plot\n",
    "    metrics = ['RAG Pearson', 'RAG Spearman', 'Log(1+d) Pearson', '1/(1+d) Pearson', 'exp(-d/10) Pearson']\n",
    "    x = np.arange(len(corr_df))\n",
    "    width = 0.15\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        offset = (i - 2) * width  # Center the bars\n",
    "        ax.bar(x + offset, corr_df[metric], width, label=metric, alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel('Unlearning Method', fontsize=12)\n",
    "    ax.set_ylabel('Correlation with Accuracy Delta', fontsize=12)\n",
    "    ax.set_title('RAG Distance Metrics: Correlation with Unlearning Effect', fontsize=14)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(corr_df['Method'])\n",
    "    ax.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    ax.legend(loc='best', ncol=3, fontsize=9)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save\n",
    "    date_str = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    filename = f\"rag_distance_correlations_{date_str}\"\n",
    "    plt.savefig(PLOT_DIR / f\"{filename}.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.savefig(PLOT_DIR / f\"{filename}.pdf\", bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Distance vs Unlearning Delta (Scatter Plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rag_vs_delta_scatter(model=\"llama\", method=\"elm\", max_distance=100):\n",
    "    \"\"\"Create scatter plot of RAG distance vs accuracy delta.\"\"\"\n",
    "    \n",
    "    if method not in UNLEARNING_RESULTS[model]:\n",
    "        print(f\"Method {method} not found for {model}\")\n",
    "        return\n",
    "    \n",
    "    # Load data\n",
    "    df_base = pd.read_csv(BASE_RESULTS[model])\n",
    "    df_unlearn = pd.read_csv(UNLEARNING_RESULTS[model][method])\n",
    "    \n",
    "    # Merge on question (or question_id if available)\n",
    "    merge_col = 'question_id' if 'question_id' in df_base.columns else 'question'\n",
    "    \n",
    "    merged = pd.merge(\n",
    "        df_base[[merge_col, 'is_correct', 'distance']],\n",
    "        df_unlearn[[merge_col, 'is_correct']],\n",
    "        on=merge_col,\n",
    "        suffixes=('_base', '_unlearn')\n",
    "    )\n",
    "    \n",
    "    # Filter by distance\n",
    "    merged = merged[merged['distance'] < max_distance]\n",
    "    \n",
    "    # Group by distance to get average delta\n",
    "    distance_groups = merged.groupby('distance').agg({\n",
    "        'is_correct_base': 'mean',\n",
    "        'is_correct_unlearn': 'mean'\n",
    "    })\n",
    "    distance_groups['accuracy_delta'] = distance_groups['is_correct_base'] - distance_groups['is_correct_unlearn']\n",
    "    \n",
    "    # Create figure with multiple subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "    \n",
    "    # Plot 1: Raw scatter\n",
    "    ax1 = axes[0, 0]\n",
    "    scatter = ax1.scatter(merged['distance'], \n",
    "                         merged['is_correct_base'] - merged['is_correct_unlearn'],\n",
    "                         alpha=0.3, s=10, c=merged['distance'], cmap='viridis')\n",
    "    ax1.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "    ax1.set_xlabel('RAG Distance')\n",
    "    ax1.set_ylabel('Accuracy Delta (Base - Unlearned)')\n",
    "    ax1.set_title(f'Individual Questions: RAG Distance vs Delta\\n{model.title()} - {method.upper()}')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Binned averages\n",
    "    ax2 = axes[0, 1]\n",
    "    ax2.plot(distance_groups.index, distance_groups['accuracy_delta'], \n",
    "            marker='o', linewidth=2, markersize=6, color='darkblue')\n",
    "    ax2.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "    ax2.set_xlabel('RAG Distance')\n",
    "    ax2.set_ylabel('Mean Accuracy Delta')\n",
    "    ax2.set_title('Average Delta by RAG Distance')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Hexbin for density\n",
    "    ax3 = axes[1, 0]\n",
    "    hexbin = ax3.hexbin(merged['distance'], \n",
    "                        merged['is_correct_base'] - merged['is_correct_unlearn'],\n",
    "                        gridsize=30, cmap='YlOrRd', mincnt=1)\n",
    "    ax3.axhline(y=0, color='white', linestyle='--', alpha=0.7)\n",
    "    ax3.set_xlabel('RAG Distance')\n",
    "    ax3.set_ylabel('Accuracy Delta (Base - Unlearned)')\n",
    "    ax3.set_title('Density Plot: RAG Distance vs Delta')\n",
    "    plt.colorbar(hexbin, ax=ax3, label='Count')\n",
    "    \n",
    "    # Plot 4: Different distance transformations\n",
    "    ax4 = axes[1, 1]\n",
    "    \n",
    "    # Calculate correlations for different transformations\n",
    "    valid_data = distance_groups.dropna()\n",
    "    distances = valid_data.index.values\n",
    "    deltas = valid_data['accuracy_delta'].values\n",
    "    \n",
    "    transformations = {\n",
    "        'RAG Distance': distances,\n",
    "        'Log(1 + d)': np.log1p(distances),\n",
    "        '1/(1 + d)': 1 / (1 + distances),\n",
    "        'exp(-d/10)': np.exp(-distances / 10)\n",
    "    }\n",
    "    \n",
    "    correlations = []\n",
    "    for name, transformed in transformations.items():\n",
    "        if len(transformed) > 2:\n",
    "            r, p = stats.pearsonr(transformed, deltas)\n",
    "            correlations.append(f\"{name}: r={r:.3f}\")\n",
    "    \n",
    "    # Plot correlations as text\n",
    "    ax4.text(0.1, 0.5, '\\n'.join(correlations), \n",
    "            transform=ax4.transAxes, fontsize=12, verticalalignment='center')\n",
    "    ax4.set_title('Distance Metric Correlations')\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    plt.suptitle(f'RAG Distance Analysis: {model.title()} - {method.upper()}', fontsize=16, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save\n",
    "    date_str = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    filename = f\"rag_distance_scatter_{model}_{method}_{date_str}\"\n",
    "    plt.savefig(PLOT_DIR / f\"{filename}.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.savefig(PLOT_DIR / f\"{filename}.pdf\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(f\"\\nSummary for {model.title()} - {method.upper()}:\")\n",
    "    print(f\"Total questions analyzed: {len(merged)}\")\n",
    "    print(f\"Mean accuracy delta: {(merged['is_correct_base'] - merged['is_correct_unlearn']).mean():.4f}\")\n",
    "    print(f\"Questions with positive delta (hurt by unlearning): {((merged['is_correct_base'] - merged['is_correct_unlearn']) > 0).sum()}\")\n",
    "    print(f\"Questions with negative delta (helped): {((merged['is_correct_base'] - merged['is_correct_unlearn']) < 0).sum()}\")\n",
    "\n",
    "# Generate scatter plots for different methods\n",
    "plot_rag_vs_delta_scatter(model=\"llama\", method=\"elm\")\n",
    "plot_rag_vs_delta_scatter(model=\"llama\", method=\"rmu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare RAG Distance Effects Across All Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_rag_effects_all_methods(model=\"llama\", bucket_size=5, max_distance=50):\n",
    "    \"\"\"Compare how RAG distance affects accuracy across all unlearning methods.\"\"\"\n",
    "    \n",
    "    METHOD_COLORS = {\n",
    "        'elm': '#FF6B6B', 'rmu': '#4ECDC4', 'graddiff': '#95E77E',\n",
    "        'pbj': '#FFD93D', 'tar': '#A8E6CF', 'rmu_lat': '#FF8B94',\n",
    "        'repnoise': '#B4A7D6', 'rr': '#FFB347'\n",
    "    }\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Load base model\n",
    "    df_base = pd.read_csv(BASE_RESULTS[model])\n",
    "    df_base = df_base[df_base['distance'] < max_distance]\n",
    "    df_base['distance_bucket'] = (df_base['distance'] // bucket_size) * bucket_size\n",
    "    base_acc = df_base.groupby('distance_bucket')['is_correct'].mean()\n",
    "    \n",
    "    # Plot 1: Accuracy vs RAG distance for all methods\n",
    "    ax1.plot(base_acc.index, base_acc.values * 100, \n",
    "            marker='o', linewidth=3, markersize=8,\n",
    "            color='black', label='Base', alpha=0.9, zorder=10)\n",
    "    \n",
    "    # Plot 2 will show deltas\n",
    "    for method, path in UNLEARNING_RESULTS[model].items():\n",
    "        if not path.exists():\n",
    "            continue\n",
    "            \n",
    "        df_unlearn = pd.read_csv(path)\n",
    "        df_unlearn = df_unlearn[df_unlearn['distance'] < max_distance]\n",
    "        df_unlearn['distance_bucket'] = (df_unlearn['distance'] // bucket_size) * bucket_size\n",
    "        unlearn_acc = df_unlearn.groupby('distance_bucket')['is_correct'].mean()\n",
    "        \n",
    "        color = METHOD_COLORS.get(method, '#888888')\n",
    "        \n",
    "        # Plot accuracy\n",
    "        ax1.plot(unlearn_acc.index, unlearn_acc.values * 100,\n",
    "                marker='s', linewidth=2, markersize=5,\n",
    "                color=color, label=method.upper().replace('_', '-'), alpha=0.7)\n",
    "        \n",
    "        # Calculate and plot delta\n",
    "        common_idx = base_acc.index.intersection(unlearn_acc.index)\n",
    "        if len(common_idx) > 0:\n",
    "            delta = base_acc.loc[common_idx] - unlearn_acc.loc[common_idx]\n",
    "            ax2.plot(common_idx, delta * 100,\n",
    "                    marker='s', linewidth=2, markersize=5,\n",
    "                    color=color, label=method.upper().replace('_', '-'), alpha=0.7)\n",
    "    \n",
    "    # Format plot 1\n",
    "    ax1.set_xlabel('RAG Distance (bucketed)', fontsize=12)\n",
    "    ax1.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "    ax1.set_title(f'Accuracy vs RAG Distance\\n{model.title()} - All Methods', fontsize=14)\n",
    "    ax1.legend(loc='best', ncol=2, fontsize=9)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_ylim(0, 100)\n",
    "    \n",
    "    # Format plot 2\n",
    "    ax2.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "    ax2.set_xlabel('RAG Distance (bucketed)', fontsize=12)\n",
    "    ax2.set_ylabel('Accuracy Delta (%)', fontsize=12)\n",
    "    ax2.set_title(f'Ripple Effect vs RAG Distance\\n{model.title()} - All Methods', fontsize=14)\n",
    "    ax2.legend(loc='best', ncol=2, fontsize=9)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save\n",
    "    date_str = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    filename = f\"rag_distance_comparison_all_methods_{model}_{date_str}\"\n",
    "    plt.savefig(PLOT_DIR / f\"{filename}.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.savefig(PLOT_DIR / f\"{filename}.pdf\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "compare_rag_effects_all_methods(model=\"llama\", bucket_size=5, max_distance=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Distance 0 (WMDP Topics) Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_wmdp_topics(model=\"llama\"):\n",
    "    \"\"\"Special analysis of topics at RAG distance 0 (WMDP topics).\"\"\"\n",
    "    \n",
    "    # Load base data\n",
    "    df_base = pd.read_csv(BASE_RESULTS[model])\n",
    "    \n",
    "    # Get WMDP topics (distance 0)\n",
    "    wmdp_topics = df_base[df_base['distance'] == 0]\n",
    "    non_wmdp = df_base[df_base['distance'] > 0]\n",
    "    \n",
    "    print(f\"\\nWMDP Topics Analysis ({model.title()}):\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"WMDP topics (distance 0): {len(wmdp_topics)} questions\")\n",
    "    print(f\"Non-WMDP topics: {len(non_wmdp)} questions\")\n",
    "    print(f\"\\nBase accuracy on WMDP: {wmdp_topics['is_correct'].mean()*100:.2f}%\")\n",
    "    print(f\"Base accuracy on non-WMDP: {non_wmdp['is_correct'].mean()*100:.2f}%\")\n",
    "    \n",
    "    # Compare unlearning effects\n",
    "    results = []\n",
    "    for method, path in UNLEARNING_RESULTS[model].items():\n",
    "        if not path.exists():\n",
    "            continue\n",
    "            \n",
    "        df_unlearn = pd.read_csv(path)\n",
    "        \n",
    "        wmdp_unlearn = df_unlearn[df_unlearn['distance'] == 0]\n",
    "        non_wmdp_unlearn = df_unlearn[df_unlearn['distance'] > 0]\n",
    "        \n",
    "        results.append({\n",
    "            'Method': method.upper(),\n",
    "            'WMDP Base Acc': wmdp_topics['is_correct'].mean() * 100,\n",
    "            'WMDP Unlearn Acc': wmdp_unlearn['is_correct'].mean() * 100,\n",
    "            'WMDP Delta': (wmdp_topics['is_correct'].mean() - wmdp_unlearn['is_correct'].mean()) * 100,\n",
    "            'Non-WMDP Base Acc': non_wmdp['is_correct'].mean() * 100,\n",
    "            'Non-WMDP Unlearn Acc': non_wmdp_unlearn['is_correct'].mean() * 100,\n",
    "            'Non-WMDP Delta': (non_wmdp['is_correct'].mean() - non_wmdp_unlearn['is_correct'].mean()) * 100\n",
    "        })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Visualize\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Plot 1: WMDP vs Non-WMDP deltas\n",
    "    x = np.arange(len(results_df))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax1.bar(x - width/2, results_df['WMDP Delta'], width, label='WMDP (d=0)', color='red', alpha=0.7)\n",
    "    ax1.bar(x + width/2, results_df['Non-WMDP Delta'], width, label='Non-WMDP (d>0)', color='blue', alpha=0.7)\n",
    "    \n",
    "    ax1.set_xlabel('Unlearning Method', fontsize=12)\n",
    "    ax1.set_ylabel('Accuracy Delta (%)', fontsize=12)\n",
    "    ax1.set_title(f'Unlearning Effect: WMDP vs Non-WMDP Topics\\n{model.title()}', fontsize=14)\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(results_df['Method'], rotation=45, ha='right')\n",
    "    ax1.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Plot 2: Scatter plot of WMDP delta vs Non-WMDP delta\n",
    "    ax2.scatter(results_df['WMDP Delta'], results_df['Non-WMDP Delta'], s=100, alpha=0.7)\n",
    "    \n",
    "    for i, row in results_df.iterrows():\n",
    "        ax2.annotate(row['Method'], \n",
    "                    (row['WMDP Delta'], row['Non-WMDP Delta']),\n",
    "                    xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "    \n",
    "    ax2.set_xlabel('WMDP Delta (%)', fontsize=12)\n",
    "    ax2.set_ylabel('Non-WMDP Delta (%)', fontsize=12)\n",
    "    ax2.set_title(f'WMDP vs Non-WMDP Unlearning Effects\\n{model.title()}', fontsize=14)\n",
    "    ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    ax2.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add diagonal line\n",
    "    lims = [min(ax2.get_xlim()[0], ax2.get_ylim()[0]),\n",
    "            max(ax2.get_xlim()[1], ax2.get_ylim()[1])]\n",
    "    ax2.plot(lims, lims, 'k--', alpha=0.3, zorder=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save\n",
    "    date_str = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    filename = f\"wmdp_vs_nonwmdp_analysis_{model}_{date_str}\"\n",
    "    plt.savefig(PLOT_DIR / f\"{filename}.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.savefig(PLOT_DIR / f\"{filename}.pdf\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nDetailed Results:\")\n",
    "    print(results_df.to_string(index=False))\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Analyze WMDP topics\n",
    "wmdp_analysis = analyze_wmdp_topics(model=\"llama\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}