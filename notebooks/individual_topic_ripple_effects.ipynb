{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup paths\n",
    "BASE_DIR = Path(\"data/eval_parallelized/\")\n",
    "BASE_DIR = Path(\"/Users/roy/data/ripple_bench/parallelized\")\n",
    "\n",
    "BASE_RESULTS = {\n",
    "    \"llama\": BASE_DIR / \"Llama-3-8b-Instruct_ripple_results.csv\",\n",
    "    \"zephyr\": BASE_DIR / \"zephyr-7b-beta_ripple_results.csv\",\n",
    "}\n",
    "\n",
    "UNLEARNING_RESULTS = {\n",
    "    \"llama\": {\n",
    "        \"elm\": BASE_DIR / \"llama-3-8b-instruct-elm-ckpt7_ripple_results.csv\",\n",
    "        \"graddiff\": BASE_DIR / \"llama-3-8b-instruct-graddiff-ckpt8_ripple_results.csv\",\n",
    "        \"pbj\": BASE_DIR / \"llama-3-8b-instruct-pbj-ckpt6_ripple_results.csv\",\n",
    "        \"repnoise\": BASE_DIR / \"llama-3-8b-instruct-repnoise-ckpt6_ripple_results.csv\",\n",
    "        \"rmu\": BASE_DIR / \"llama-3-8b-instruct-rmu-ckpt6_ripple_results.csv\",\n",
    "        \"rmu_lat\": BASE_DIR / \"llama-3-8b-instruct-rmu-lat-ckpt7_ripple_results.csv\",\n",
    "        \"rr\": BASE_DIR / \"llama-3-8b-instruct-rr-ckpt8_ripple_results.csv\",\n",
    "        \"tar\": BASE_DIR / \"llama-3-8b-instruct-tar-ckpt8_ripple_results.csv\",\n",
    "    },\n",
    "    \"zephyr\": {\n",
    "        \"elm\": BASE_DIR / \"zephyr-7b-elm_ripple_results.csv\",\n",
    "    }\n",
    "}\n",
    "\n",
    "PLOT_DIR = Path(\"plots/\")\n",
    "PLOT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Individual Topics\n",
    "\n",
    "First, let's see what topics are available in the dataset and how many questions each has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total unique questions: 49247\n",
      "Total data points: 229648\n",
      "\n",
      "Available columns: ['question_id', 'question', 'choices', 'correct_answer', 'model_response', 'is_correct', 'topic', 'distance', 'model_name']\n"
     ]
    }
   ],
   "source": [
    "# Load base Llama results to explore topics\n",
    "df_base = pd.read_csv(BASE_RESULTS[\"llama\"])\n",
    "\n",
    "# Extract topic from question (assuming format like \"[topic] question text\")\n",
    "# Or if there's a topic column, use that\n",
    "if 'topic' in df_base.columns:\n",
    "    topics = df_base['topic'].value_counts()\n",
    "else:\n",
    "    # Try to extract from question or source_topic\n",
    "    if 'source_topic' in df_base.columns:\n",
    "        topics = df_base['source_topic'].value_counts()\n",
    "    else:\n",
    "        # If topics are embedded in questions, extract them\n",
    "        # This assumes questions might have a pattern we can extract\n",
    "        topics = df_base.groupby('question')['distance'].first().reset_index()\n",
    "        print(\"Sample questions to identify topic pattern:\")\n",
    "        print(df_base['question'].head(10))\n",
    "        \n",
    "print(f\"\\nTotal unique questions: {df_base['question'].nunique()}\")\n",
    "print(f\"Total data points: {len(df_base)}\")\n",
    "print(f\"\\nAvailable columns: {df_base.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows to understand data structure:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>choices</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>model_response</th>\n",
       "      <th>is_correct</th>\n",
       "      <th>topic</th>\n",
       "      <th>distance</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Approximately how long ago did bacteria first ...</td>\n",
       "      <td>A) 1 billion years ago|B) 2 billion years ago|...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "      <td>Bacterial isolation</td>\n",
       "      <td>0</td>\n",
       "      <td>Llama-3-8b-Instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What percentage of the estimated 43,000 named ...</td>\n",
       "      <td>A) Less than 1%|B) About 5%|C) Approximately 1...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>True</td>\n",
       "      <td>Bacterial isolation</td>\n",
       "      <td>0</td>\n",
       "      <td>Llama-3-8b-Instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Which structural characteristic distinguishes ...</td>\n",
       "      <td>A) They have linear chromosomes|B) They contai...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "      <td>Bacterial isolation</td>\n",
       "      <td>0</td>\n",
       "      <td>Llama-3-8b-Instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Approximately how many bacteria do humans carr...</td>\n",
       "      <td>A) 10¹⁰ to 10¹¹|B) 10¹³ to 10¹⁴|C) 10¹⁵ to 10¹...</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>False</td>\n",
       "      <td>Bacterial isolation</td>\n",
       "      <td>0</td>\n",
       "      <td>Llama-3-8b-Instruct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>What major evolutionary contribution did bacte...</td>\n",
       "      <td>A) They formed the cell nucleus through fusion...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "      <td>Bacterial isolation</td>\n",
       "      <td>0</td>\n",
       "      <td>Llama-3-8b-Instruct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_id                                           question  \\\n",
       "0            0  Approximately how long ago did bacteria first ...   \n",
       "1            1  What percentage of the estimated 43,000 named ...   \n",
       "2            2  Which structural characteristic distinguishes ...   \n",
       "3            3  Approximately how many bacteria do humans carr...   \n",
       "4            4  What major evolutionary contribution did bacte...   \n",
       "\n",
       "                                             choices correct_answer  \\\n",
       "0  A) 1 billion years ago|B) 2 billion years ago|...              C   \n",
       "1  A) Less than 1%|B) About 5%|C) Approximately 1...              A   \n",
       "2  A) They have linear chromosomes|B) They contai...              C   \n",
       "3  A) 10¹⁰ to 10¹¹|B) 10¹³ to 10¹⁴|C) 10¹⁵ to 10¹...              B   \n",
       "4  A) They formed the cell nucleus through fusion...              C   \n",
       "\n",
       "  model_response  is_correct                topic  distance  \\\n",
       "0              C        True  Bacterial isolation         0   \n",
       "1              A        True  Bacterial isolation         0   \n",
       "2              C        True  Bacterial isolation         0   \n",
       "3              C       False  Bacterial isolation         0   \n",
       "4              C        True  Bacterial isolation         0   \n",
       "\n",
       "            model_name  \n",
       "0  Llama-3-8b-Instruct  \n",
       "1  Llama-3-8b-Instruct  \n",
       "2  Llama-3-8b-Instruct  \n",
       "3  Llama-3-8b-Instruct  \n",
       "4  Llama-3-8b-Instruct  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check if there's a source_topic or any topic-related column\n",
    "print(\"First few rows to understand data structure:\")\n",
    "df_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No 'source_topic' column found. Will need to extract topics differently.\n"
     ]
    }
   ],
   "source": [
    "# Assuming we have source_topic column, let's analyze topics\n",
    "if 'source_topic' in df_base.columns:\n",
    "    topic_counts = df_base.groupby('source_topic').agg({\n",
    "        'question': 'nunique',\n",
    "        'is_correct': 'count'\n",
    "    }).rename(columns={'question': 'unique_questions', 'is_correct': 'total_evaluations'})\n",
    "    \n",
    "    topic_counts = topic_counts.sort_values('total_evaluations', ascending=False)\n",
    "    print(\"Top 20 topics by number of evaluations:\")\n",
    "    print(topic_counts.head(20))\n",
    "    \n",
    "    # Store top topics for later use\n",
    "    top_topics = topic_counts.head(10).index.tolist()\n",
    "else:\n",
    "    print(\"No 'source_topic' column found. Will need to extract topics differently.\")\n",
    "    # You might need to parse topics from questions or another field\n",
    "    top_topics = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ripple Effects for Individual Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_topic_df(path, topic, bucket_size=10, max_distance=100):\n",
    "    \"\"\"Load dataframe and filter for specific topic.\"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    # Filter for specific topic\n",
    "    if 'source_topic' in df.columns:\n",
    "        df = df[df['source_topic'] == topic]\n",
    "    else:\n",
    "        print(f\"Warning: No 'source_topic' column found\")\n",
    "    \n",
    "    df = df[df[\"distance\"] < max_distance]\n",
    "    df[\"distance_bucket\"] = (df[\"distance\"] // bucket_size) * bucket_size\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_topic_results(df):\n",
    "    \"\"\"Get accuracy results by distance bucket for a topic.\"\"\"\n",
    "    if len(df) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    results = df.groupby(\"distance_bucket\")[\"is_correct\"].agg([\"mean\", \"std\", \"count\"])\n",
    "    results[\"sem\"] = results[\"std\"] / np.sqrt(results[\"count\"])\n",
    "    return results\n",
    "\n",
    "def get_topic_dedup_results(df):\n",
    "    \"\"\"Get deduplicated accuracy results by distance bucket for a topic.\"\"\"\n",
    "    if len(df) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    df_dedup = df.groupby(\"question\")[[\"is_correct\", \"distance_bucket\"]].agg(\n",
    "        {\"is_correct\": [\"max\", \"min\", \"sum\", \"count\", \"mean\"],\n",
    "         \"distance_bucket\": \"min\"}\n",
    "    )\n",
    "    \n",
    "    results = df_dedup.groupby(df_dedup[\"distance_bucket\"][\"min\"]).agg(\n",
    "        {(\"is_correct\", \"mean\"): [\"mean\", \"std\", \"count\"]}\n",
    "    )\n",
    "    results.columns = [\"mean\", \"std\", \"count\"]\n",
    "    results[\"sem\"] = results[\"std\"] / np.sqrt(results[\"count\"])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_topic_ripple_effect(topic, model=\"llama\", dedup=False, save=True):\n",
    "    \"\"\"Plot ripple effect for a specific topic.\"\"\"\n",
    "    \n",
    "    # Method colors - consistent across models\n",
    "    METHOD_COLORS = {\n",
    "        'elm': '#FF6B6B',      # Red\n",
    "        'rmu': '#4ECDC4',      # Teal\n",
    "        'graddiff': '#95E77E', # Light green\n",
    "        'pbj': '#FFD93D',      # Yellow\n",
    "        'tar': '#A8E6CF',      # Mint\n",
    "        'rmu_lat': '#FF8B94',  # Pink\n",
    "        'repnoise': '#B4A7D6', # Lavender\n",
    "        'rr': '#FFB347'        # Orange\n",
    "    }\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Choose results function based on dedup\n",
    "    results_fn = get_topic_dedup_results if dedup else get_topic_results\n",
    "    \n",
    "    # Load base model data for this topic\n",
    "    base_df = load_topic_df(BASE_RESULTS[model], topic)\n",
    "    base_results = results_fn(base_df)\n",
    "    \n",
    "    if len(base_results) == 0:\n",
    "        print(f\"No data found for topic: {topic}\")\n",
    "        return\n",
    "    \n",
    "    # Plot 1: Absolute accuracies\n",
    "    ax1.errorbar(\n",
    "        base_results.index,\n",
    "        base_results[\"mean\"] * 100,\n",
    "        yerr=base_results[\"sem\"] * 100,\n",
    "        marker='o',\n",
    "        linewidth=3,\n",
    "        markersize=8,\n",
    "        capsize=4,\n",
    "        color='black',\n",
    "        alpha=0.9,\n",
    "        label=f\"{model.title()} Base\",\n",
    "        zorder=10\n",
    "    )\n",
    "    \n",
    "    # Plot each unlearning method\n",
    "    for method, path in UNLEARNING_RESULTS[model].items():\n",
    "        unlearn_df = load_topic_df(path, topic)\n",
    "        unlearn_results = results_fn(unlearn_df)\n",
    "        \n",
    "        if len(unlearn_results) == 0:\n",
    "            continue\n",
    "        \n",
    "        color = METHOD_COLORS.get(method, '#888888')\n",
    "        \n",
    "        ax1.errorbar(\n",
    "            unlearn_results.index,\n",
    "            unlearn_results[\"mean\"] * 100,\n",
    "            yerr=unlearn_results[\"sem\"] * 100,\n",
    "            marker='s',\n",
    "            linewidth=2,\n",
    "            markersize=6,\n",
    "            capsize=3,\n",
    "            color=color,\n",
    "            alpha=0.8,\n",
    "            label=method.upper().replace('_', '-')\n",
    "        )\n",
    "    \n",
    "    ax1.set_xlabel(\"Distance Bucket\", fontsize=12)\n",
    "    ax1.set_ylabel(\"Accuracy (%)\", fontsize=12)\n",
    "    ax1.set_title(f\"Topic: {topic}\\nAccuracy vs Distance\", fontsize=14)\n",
    "    ax1.legend(loc=\"best\", fontsize=10)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_ylim(0, 100)\n",
    "    \n",
    "    # Plot 2: Delta from base\n",
    "    for method, path in UNLEARNING_RESULTS[model].items():\n",
    "        unlearn_df = load_topic_df(path, topic)\n",
    "        unlearn_results = results_fn(unlearn_df)\n",
    "        \n",
    "        if len(unlearn_results) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Calculate delta where both base and unlearn have data\n",
    "        common_indices = base_results.index.intersection(unlearn_results.index)\n",
    "        if len(common_indices) == 0:\n",
    "            continue\n",
    "            \n",
    "        delta = base_results.loc[common_indices, \"mean\"] - unlearn_results.loc[common_indices, \"mean\"]\n",
    "        \n",
    "        # Error propagation\n",
    "        error_prop = np.sqrt(\n",
    "            base_results.loc[common_indices, \"sem\"]**2 + \n",
    "            unlearn_results.loc[common_indices, \"sem\"]**2\n",
    "        )\n",
    "        \n",
    "        color = METHOD_COLORS.get(method, '#888888')\n",
    "        \n",
    "        ax2.errorbar(\n",
    "            common_indices,\n",
    "            delta * 100,\n",
    "            yerr=error_prop * 100,\n",
    "            marker='s',\n",
    "            linewidth=2,\n",
    "            markersize=6,\n",
    "            capsize=3,\n",
    "            color=color,\n",
    "            alpha=0.8,\n",
    "            label=method.upper().replace('_', '-')\n",
    "        )\n",
    "    \n",
    "    ax2.axhline(y=0, color='gray', linestyle=':', alpha=0.5)\n",
    "    ax2.set_xlabel(\"Distance Bucket\", fontsize=12)\n",
    "    ax2.set_ylabel(\"Accuracy Delta (Base - Unlearned) %\", fontsize=12)\n",
    "    ax2.set_title(f\"Topic: {topic}\\nRipple Effect (Delta)\", fontsize=14)\n",
    "    ax2.legend(loc=\"best\", fontsize=10)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save:\n",
    "        date_str = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        dedup_str = \"_dedup\" if dedup else \"\"\n",
    "        safe_topic = topic.replace(\"/\", \"_\").replace(\" \", \"_\")\n",
    "        filename = f\"ripple_topic_{safe_topic}_{model}{dedup_str}_{date_str}\"\n",
    "        plt.savefig(PLOT_DIR / f\"{filename}.png\", dpi=150, bbox_inches='tight')\n",
    "        plt.savefig(PLOT_DIR / f\"{filename}.pdf\", bbox_inches='tight')\n",
    "        print(f\"Saved plot to {PLOT_DIR / filename}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"\\nStatistics for topic: {topic}\")\n",
    "    print(f\"Base model: {len(base_df)} evaluations, {base_df['question'].nunique()} unique questions\")\n",
    "    print(f\"Distance range: {base_df['distance'].min():.0f} - {base_df['distance'].max():.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please specify a topic to plot\n"
     ]
    }
   ],
   "source": [
    "# Plot ripple effects for top topics\n",
    "if top_topics:\n",
    "    # Plot first topic as example\n",
    "    topic_to_plot = top_topics[0]\n",
    "    print(f\"Plotting ripple effect for topic: {topic_to_plot}\")\n",
    "    plot_topic_ripple_effect(topic_to_plot, model=\"llama\", dedup=False)\n",
    "else:\n",
    "    print(\"Please specify a topic to plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare dedup vs non-dedup for same topic\n",
    "if top_topics:\n",
    "    topic_to_plot = top_topics[0]\n",
    "    print(f\"\\n=== Non-deduplicated results ===\")\n",
    "    plot_topic_ripple_effect(topic_to_plot, model=\"llama\", dedup=False)\n",
    "    \n",
    "    print(f\"\\n=== Deduplicated results ===\")\n",
    "    plot_topic_ripple_effect(topic_to_plot, model=\"llama\", dedup=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Topic Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiple_topics(topics_list, model=\"llama\", dedup=False, max_topics=6):\n",
    "    \"\"\"Plot ripple effects for multiple topics in a grid.\"\"\"\n",
    "    \n",
    "    METHOD_COLORS = {\n",
    "        'elm': '#FF6B6B',      # Red\n",
    "        'rmu': '#4ECDC4',      # Teal\n",
    "        'graddiff': '#95E77E', # Light green\n",
    "        'pbj': '#FFD93D',      # Yellow\n",
    "        'tar': '#A8E6CF',      # Mint\n",
    "        'rmu_lat': '#FF8B94',  # Pink\n",
    "        'repnoise': '#B4A7D6', # Lavender\n",
    "        'rr': '#FFB347'        # Orange\n",
    "    }\n",
    "    \n",
    "    n_topics = min(len(topics_list), max_topics)\n",
    "    n_cols = 2\n",
    "    n_rows = (n_topics + 1) // 2\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(14, 5*n_rows))\n",
    "    axes = axes.flatten() if n_topics > 2 else [axes] if n_topics == 1 else axes\n",
    "    \n",
    "    results_fn = get_topic_dedup_results if dedup else get_topic_results\n",
    "    \n",
    "    for idx, topic in enumerate(topics_list[:n_topics]):\n",
    "        ax = axes[idx] if n_topics > 1 else axes\n",
    "        \n",
    "        # Load base model data\n",
    "        base_df = load_topic_df(BASE_RESULTS[model], topic)\n",
    "        base_results = results_fn(base_df)\n",
    "        \n",
    "        if len(base_results) == 0:\n",
    "            ax.text(0.5, 0.5, f\"No data for\\n{topic}\", \n",
    "                   ha='center', va='center', transform=ax.transAxes)\n",
    "            ax.set_title(f\"Topic: {topic[:30]}...\" if len(topic) > 30 else f\"Topic: {topic}\")\n",
    "            continue\n",
    "        \n",
    "        # Plot base\n",
    "        ax.errorbar(\n",
    "            base_results.index,\n",
    "            base_results[\"mean\"] * 100,\n",
    "            yerr=base_results[\"sem\"] * 100,\n",
    "            marker='o',\n",
    "            linewidth=2.5,\n",
    "            markersize=6,\n",
    "            capsize=3,\n",
    "            color='black',\n",
    "            alpha=0.9,\n",
    "            label=\"Base\"\n",
    "        )\n",
    "        \n",
    "        # Plot unlearning methods\n",
    "        for method, path in UNLEARNING_RESULTS[model].items():\n",
    "            unlearn_df = load_topic_df(path, topic)\n",
    "            unlearn_results = results_fn(unlearn_df)\n",
    "            \n",
    "            if len(unlearn_results) == 0:\n",
    "                continue\n",
    "            \n",
    "            color = METHOD_COLORS.get(method, '#888888')\n",
    "            \n",
    "            ax.errorbar(\n",
    "                unlearn_results.index,\n",
    "                unlearn_results[\"mean\"] * 100,\n",
    "                yerr=unlearn_results[\"sem\"] * 100,\n",
    "                marker='s',\n",
    "                linewidth=1.5,\n",
    "                markersize=4,\n",
    "                capsize=2,\n",
    "                color=color,\n",
    "                alpha=0.7,\n",
    "                label=method.upper()[:3]\n",
    "            )\n",
    "        \n",
    "        ax.set_xlabel(\"Distance\", fontsize=10)\n",
    "        ax.set_ylabel(\"Accuracy (%)\", fontsize=10)\n",
    "        title = f\"{topic[:25]}...\" if len(topic) > 25 else topic\n",
    "        ax.set_title(title, fontsize=11)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_ylim(0, 100)\n",
    "        \n",
    "        if idx == 0:\n",
    "            ax.legend(loc=\"best\", fontsize=8, ncol=2)\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(n_topics, len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.suptitle(f\"Ripple Effects by Topic - {model.title()} {'(Dedup)' if dedup else '(Raw)'}\", \n",
    "                 fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save\n",
    "    date_str = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    dedup_str = \"_dedup\" if dedup else \"\"\n",
    "    filename = f\"ripple_topics_grid_{model}{dedup_str}_{date_str}\"\n",
    "    plt.savefig(PLOT_DIR / f\"{filename}.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.savefig(PLOT_DIR / f\"{filename}.pdf\", bbox_inches='tight')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot grid of top topics\n",
    "if top_topics:\n",
    "    print(\"Plotting top 6 topics in a grid...\")\n",
    "    plot_multiple_topics(top_topics[:6], model=\"llama\", dedup=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic-Specific Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_topic_performance(topic, model=\"llama\"):\n",
    "    \"\"\"Detailed analysis of a specific topic's performance.\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Topic Analysis: {topic}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Load base model data\n",
    "    base_df = load_topic_df(BASE_RESULTS[model], topic, max_distance=1000)\n",
    "    \n",
    "    if len(base_df) == 0:\n",
    "        print(f\"No data found for topic: {topic}\")\n",
    "        return\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(f\"Base Model Statistics:\")\n",
    "    print(f\"  - Total evaluations: {len(base_df)}\")\n",
    "    print(f\"  - Unique questions: {base_df['question'].nunique()}\")\n",
    "    print(f\"  - Overall accuracy: {base_df['is_correct'].mean()*100:.1f}%\")\n",
    "    print(f\"  - Distance range: {base_df['distance'].min():.0f} - {base_df['distance'].max():.0f}\")\n",
    "    \n",
    "    # Performance by distance buckets\n",
    "    print(f\"\\nAccuracy by Distance (0-50):\")\n",
    "    for dist in range(0, 60, 10):\n",
    "        mask = (base_df['distance'] >= dist) & (base_df['distance'] < dist + 10)\n",
    "        if mask.sum() > 0:\n",
    "            acc = base_df[mask]['is_correct'].mean() * 100\n",
    "            count = mask.sum()\n",
    "            print(f\"  Distance {dist:2d}-{dist+9:2d}: {acc:5.1f}% (n={count:4d})\")\n",
    "    \n",
    "    # Compare unlearning methods\n",
    "    print(f\"\\nUnlearning Method Performance (Distance 0-30):\")\n",
    "    results_summary = {}\n",
    "    \n",
    "    for method, path in UNLEARNING_RESULTS[model].items():\n",
    "        unlearn_df = load_topic_df(path, topic, max_distance=30)\n",
    "        if len(unlearn_df) > 0:\n",
    "            acc = unlearn_df['is_correct'].mean() * 100\n",
    "            base_acc_same_range = base_df[base_df['distance'] < 30]['is_correct'].mean() * 100\n",
    "            delta = base_acc_same_range - acc\n",
    "            results_summary[method] = (acc, delta)\n",
    "            print(f\"  {method.upper():10s}: {acc:5.1f}% (Δ={delta:+5.1f}%)\")\n",
    "    \n",
    "    # Find best and worst performing methods\n",
    "    if results_summary:\n",
    "        best_method = min(results_summary.items(), key=lambda x: x[1][1])\n",
    "        worst_method = max(results_summary.items(), key=lambda x: x[1][1])\n",
    "        \n",
    "        print(f\"\\nSummary:\")\n",
    "        print(f\"  - Smallest ripple effect: {best_method[0].upper()} (Δ={best_method[1][1]:+.1f}%)\")\n",
    "        print(f\"  - Largest ripple effect: {worst_method[0].upper()} (Δ={worst_method[1][1]:+.1f}%)\")\n",
    "    \n",
    "    return base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze specific topics\n",
    "if top_topics:\n",
    "    for topic in top_topics[:3]:  # Analyze top 3 topics\n",
    "        df_analysis = analyze_topic_performance(topic, model=\"llama\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Topic Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set custom_topic variable to analyze a specific topic\n"
     ]
    }
   ],
   "source": [
    "# Manually specify a topic to analyze\n",
    "# Replace with actual topic name from your dataset\n",
    "custom_topic = \"\"  # e.g., \"Nuclear weapons\" or whatever topics exist in your data\n",
    "\n",
    "if custom_topic:\n",
    "    print(f\"Analyzing custom topic: {custom_topic}\")\n",
    "    plot_topic_ripple_effect(custom_topic, model=\"llama\", dedup=False)\n",
    "    analyze_topic_performance(custom_topic, model=\"llama\")\n",
    "else:\n",
    "    print(\"Set custom_topic variable to analyze a specific topic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No source_topic column found\n"
     ]
    }
   ],
   "source": [
    "# Find topics with interesting patterns\n",
    "def find_interesting_topics(model=\"llama\", min_questions=50):\n",
    "    \"\"\"Find topics with strong ripple effects.\"\"\"\n",
    "    \n",
    "    base_df = pd.read_csv(BASE_RESULTS[model])\n",
    "    \n",
    "    if 'source_topic' not in base_df.columns:\n",
    "        print(\"No source_topic column found\")\n",
    "        return []\n",
    "    \n",
    "    # Get topics with enough data\n",
    "    topic_sizes = base_df.groupby('source_topic').size()\n",
    "    valid_topics = topic_sizes[topic_sizes >= min_questions].index.tolist()\n",
    "    \n",
    "    print(f\"Found {len(valid_topics)} topics with at least {min_questions} questions\\n\")\n",
    "    \n",
    "    # Calculate ripple strength for each topic\n",
    "    ripple_scores = {}\n",
    "    \n",
    "    for topic in valid_topics[:20]:  # Check first 20 topics\n",
    "        # Get base accuracy at distance 0-10 vs 20-30\n",
    "        topic_data = base_df[base_df['source_topic'] == topic]\n",
    "        \n",
    "        near_acc = topic_data[topic_data['distance'] < 10]['is_correct'].mean()\n",
    "        far_acc = topic_data[(topic_data['distance'] >= 20) & \n",
    "                            (topic_data['distance'] < 30)]['is_correct'].mean()\n",
    "        \n",
    "        if not pd.isna(near_acc) and not pd.isna(far_acc):\n",
    "            # Higher score = stronger distance effect\n",
    "            ripple_scores[topic] = near_acc - far_acc\n",
    "    \n",
    "    # Sort by ripple strength\n",
    "    sorted_topics = sorted(ripple_scores.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "    \n",
    "    print(\"Topics with strongest distance effects:\")\n",
    "    for topic, score in sorted_topics[:10]:\n",
    "        print(f\"  {topic[:40]:40s}: {score*100:+5.1f}% difference\")\n",
    "    \n",
    "    return [t[0] for t in sorted_topics[:6]]\n",
    "\n",
    "interesting_topics = find_interesting_topics(model=\"llama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the most interesting topics\n",
    "if interesting_topics:\n",
    "    print(\"\\nPlotting topics with strongest ripple effects...\")\n",
    "    plot_multiple_topics(interesting_topics, model=\"llama\", dedup=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
