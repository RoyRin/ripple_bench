{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293\n",
      "382\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "def estimate_token_count(text: str, model: str = \"gpt-4\") -> int:\n",
    "    \"\"\"\n",
    "    Estimates the number of tokens in a string for a given OpenAI model.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input string.\n",
    "        model (str): The model name (e.g., \"gpt-3.5-turbo\", \"gpt-4\", etc.)\n",
    "\n",
    "    Returns:\n",
    "        int: Estimated token count.\n",
    "    \"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    tokens = encoding.encode(text)\n",
    "    return len(tokens)\n",
    "\n",
    "\n",
    "string= ['- 1.1.1.1 is a free Domain Name System (DNS) service by Cloudflare in partnership with APNIC.',\n",
    " '- The service functions as a recursive name server, providing domain name resolution for any host on the Internet.',\n",
    " '- It was announced on April 1, 2018.',\n",
    " '- Cloudflare released a mobile application for Android and iOS on November 11, 2018.',\n",
    " '- On September 25, 2019, Cloudflare released WARP, an upgraded version of their original 1.1.1.1 mobile application.',\n",
    " '- The service operates recursive name servers for public use at twelve IP addresses.',\n",
    " '- These addresses are mapped to the nearest operational server by anycast routing.',\n",
    " '- The service is also available for Tor clients.',\n",
    " '- Users can set up the service by manually changing their DNS resolvers to the IP addresses.',\n",
    " '- The mobile application automatically configures the DNS resolvers on the device.',\n",
    " '- The service is a recursive DNS resolver.',\n",
    " '- Cloudflare runs an authoritative DNS resolver with a network of over 20 million Internet properties.',\n",
    " '- The service allows users to encrypt their DNS queries over HTTPS (DoH) or TLS (DoT).',\n",
    " \"- The mobile application also includes a VPN tunnel based on Cloudflare's own BoringTun.\",\n",
    " '- Before 2010, the IP block was unassigned space.',\n",
    " '- Many existing routers and companies abused the simplicity of the address, rendering the proper routing of impossible on'\n",
    " ]\n",
    "str_ = ' '.join(string)\n",
    "\n",
    "print(estimate_token_count(str_))\n",
    "\n",
    "str_2 = \"\"\" [{'question': 'Who provides the free Domain Name System (DNS) service 1.1.1.1?',\n",
    "  'choices': ['Microsoft',\n",
    "   'Amazon',\n",
    "   'Cloudflare in partnership with APNIC',\n",
    "   'Google'],\n",
    "  'answer': 'Cloudflare in partnership with APNIC',\n",
    "  'answer_ind': 2},\n",
    " {'question': 'When was the 1.1.1.1 service first announced?',\n",
    "  'choices': ['April 1, 2017',\n",
    "   'April 1, 2018',\n",
    "   'April 1, 2019',\n",
    "   'April 1, 2020'],\n",
    "  'answer': 'April 1, 2018',\n",
    "  'answer_ind': 1},\n",
    " {'question': 'What is the upgraded version of the original 1.1.1.1 mobile application released by Cloudflare?',\n",
    "  'choices': ['RAID', 'WARP', 'FLASH', 'SWIFT'],\n",
    "  'answer': 'WARP',\n",
    "  'answer_ind': 1},\n",
    " {'question': 'How can users set up the 1.1.1.1 service?',\n",
    "  'choices': ['By downloading a program',\n",
    "   'By manually changing their DNS resolvers to the IP addresses',\n",
    "   'By subscribing to a plan',\n",
    "   'By contacting their internet service provider'],\n",
    "  'answer': 'By manually changing their DNS resolvers to the IP addresses',\n",
    "  'answer_ind': 1},\n",
    " {'question': 'What additional feature does the mobile application of 1.1.1.1 include?',\n",
    "  'choices': ['Email service',\n",
    "   'Instant messaging',\n",
    "   \"VPN tunnel based on Cloudflare's own BoringTun\",\n",
    "   'Video streaming'],\n",
    "  'answer': \"VPN tunnel based on Cloudflare's own BoringTun\",\n",
    "  'answer_ind': 2}]\"\"\"\n",
    "  \n",
    "print(estimate_token_count(str_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logic:\n",
    "# 1. get topic\n",
    "# 2. extract question if we already have it\n",
    "# 3. see if model is correct\n",
    "# 4. if yes, keep question\n",
    "# 5. if not, ask OpenAI for another question\n",
    "def find_answerable_questions(starting_topic, model, tokenizer, seen_topics,\n",
    "                              existing_hop_dataset):\n",
    "    row_ = get_OA_question(starting_topic, seen_topics, existing_hop_dataset)\n",
    "    # TODO - if not seen, then generate one, and add it to the DF\n",
    "    correct_ = base_model_gets_question_correct(row_, model, tokenizer)\n",
    "    print(f\"model gets {hop_topic} correct: {correct_}\")\n",
    "    if correct_:\n",
    "        return\n",
    "    related_topic = suggest_related_topic(model,\n",
    "                                          tokenizer,\n",
    "                                          starting_topic,\n",
    "                                          max_tokens=20)\n",
    "    related_topic = clean_related_topic(related_topic)\n",
    "    # get new topic from model\n",
    "\n",
    "    # get nearest wikipedia article topic\n",
    "\n",
    "    true_false_response = create_true_false_statements_about_subject(\n",
    "        related_topic)\n",
    "    question = f\"Which of the following statements is true about {related_topic}?\"\n",
    "    choices = np.array(true_false_response.split(\"\\n\"))\n",
    "    choices = remove_leading_number(choices)\n",
    "    try:\n",
    "        single_dual_use_df = construct_single_dual_use_df_row(\n",
    "            question, choices)\n",
    "        print(f\"single_dual_use_df: {single_dual_use_df}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row {row_ind}: {e}\")\n",
    "        print(f\"Choices: {choices}; len - {len(choices)}\")\n",
    "    if hop_dataset is None:\n",
    "        hop_dataset = single_dual_use_df\n",
    "    else:\n",
    "        hop_dataset = pd.concat([hop_dataset, single_dual_use_df],\n",
    "                                ignore_index=True)\n",
    "\n",
    "\n",
    "# TODO: we are building a suite to set up a framework for testing out ripples of infromation for information removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ask openai for facts about hop_0\n",
    "import re\n",
    "\n",
    "\n",
    "def remove_leading_number(sentences):\n",
    "    return [re.sub(r'^\\d+\\.\\s*', '', s) for s in sentences]\n",
    "\n",
    "\n",
    "do_basic = True\n",
    "basic_str = \"basic \"\n",
    "\n",
    "\n",
    "def create_true_false_statements_about_subject(subject,\n",
    "                                               verbose=False\n",
    "                                               ):  # df, row_ind,):\n",
    "    #row = df.iloc[row_ind]\n",
    "\n",
    "    #return subject, \"\"\n",
    "    dual_use_prompt = f\"tell me a 1 {basic_str}true statement and 3 {basic_str}false statement that uses the fact about {subject}. Make the statements not dangerous. Have the true statement be the first one. and separate the responses by `\\\\n`\"\n",
    "    if verbose:\n",
    "        print(f\"{dual_use_prompt}\")\n",
    "    if USE_HUIT_OAI_TOKEN:\n",
    "        dual_use_answers = huit_OAI_function(dual_use_prompt).strip()\n",
    "        \n",
    "    else:\n",
    "        dual_use_answers = client.chat.completions.create(model=\"gpt-4o-mini\",\n",
    "                                                      store=True,\n",
    "                                                      messages=[{\n",
    "                                                          \"role\":\n",
    "                                                          \"user\",\n",
    "                                                          \"content\":\n",
    "                                                          dual_use_prompt\n",
    "                                                      }])\n",
    "    true_false_response = dual_use_answers.choices[0].message.content.strip()\n",
    "\n",
    "    return true_false_response\n",
    "\n",
    "\n",
    "seen_topics = set()\n",
    "hop_dataset = None\n",
    "\n",
    "basic_str = \"__basic\" if do_basic else \"\"\n",
    "hop_df_savepath = f\"safe_fact_hop_dataset{basic_str}.json\"\n",
    "# load from json if exists\n",
    "\n",
    "if os.path.exists(hop_df_savepath):\n",
    "    # load pandas\n",
    "    hop_dataset = pd.read_json(hop_df_savepath, orient=\"records\", lines=True)\n",
    "    seen_topics = set(hop_dataset.subject)\n",
    "\n",
    "for row_ind, row in dual_use_df.iterrows():\n",
    "    hop_topics = [row.hop_0, row.hop_1, row.hop_2, row.hop_3, row.hop_4]\n",
    "    print(f\"hop_topics- {hop_topics}\")\n",
    "    for hop_ind, hop_topic in enumerate(hop_topics):\n",
    "        if hop_topic in seen_topics:\n",
    "            continue\n",
    "        seen_topics.add(hop_topic)\n",
    "        print(f\"processing topic: {hop_topic}\")\n",
    "        true_false_response = create_true_false_statements_about_subject(\n",
    "            hop_topic)\n",
    "        question = f\"Which of the following statements is true about {hop_topic}?\"\n",
    "\n",
    "        choices = np.array(true_false_response.split(\"\\n\"))\n",
    "        choices = remove_leading_number(choices)\n",
    "        try:\n",
    "            single_dual_use_df = construct_single_dual_use_df_row(\n",
    "                question, choices)\n",
    "            print(f\"single_dual_use_df: {single_dual_use_df}\")\n",
    "            # add column \"row_ind\"\n",
    "            single_dual_use_df['row_ind'] = row_ind\n",
    "            single_dual_use_df['hop_ind'] = hop_ind\n",
    "            single_dual_use_df[\"subject\"] = hop_topic\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {row_ind}: {e}\")\n",
    "            print(f\"Choices: {choices}; len - {len(choices)}\")\n",
    "            continue\n",
    "        if hop_dataset is None:\n",
    "            hop_dataset = single_dual_use_df\n",
    "        else:\n",
    "            hop_dataset = pd.concat([hop_dataset, single_dual_use_df],\n",
    "                                    ignore_index=True)\n",
    "\n",
    "    # save every 10\n",
    "    print(f\"Saving dual_use_dataframe with {len(hop_dataset)} rows\")\n",
    "    hop_dataset.to_json(hop_df_savepath, orient=\"records\", lines=True)\n",
    "    if row_ind >= 50:\n",
    "        break\n",
    "\n",
    "print(f\"hop_dataset shape: {hop_dataset.shape}\")\n",
    "\n",
    "if False:\n",
    "    dual_use_df.iloc[0].hop_1\n",
    "    #qa_response= create_hop_questions(dual_use_df.iloc[0].hop_1)\n",
    "    qa_response\n",
    "hop_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perhaps we can use wikipedia counts into order to identify \"reasonable\" topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's evaluate if model can do well on these\n",
    "# we need some way to make it not hyper niche; perhaps we can weight them by popularity - something we computed before hand\n",
    "\n",
    "reload(rag_wikipedia)\n",
    "\n",
    "asset_dir = Path(\n",
    "    \"/n/home04/rrinberg/code/data_to_concept_unlearning/wiki-rag/assets\")\n",
    "\n",
    "output_f = asset_dir / 'english_pageviews.csv'\n",
    "stats_f = asset_dir / 'pageviews-20241201-000000'\n",
    "print(f\"loading english df from {output_f}\")\n",
    "english_df = rag_wikipedia.get_sorted_english_df(\n",
    "    output_f, stats_f, save=False)  # output - where to output, stats_f base\n",
    "\n",
    "english_df.head()\n",
    "top_1k_topics = english_df.head(2000)\n",
    "top_1k_topics = {\n",
    "    rag_wikipedia.clean_title(row.page_title): row.views\n",
    "    for _, row in top_1k_topics.iterrows()\n",
    "}\n",
    "top_1k_topics\n",
    "dual_use_df.head()\n",
    "#\n",
    "for i, subject in enumerate(dual_use_df.subject):\n",
    "    original_q = df_bio.iloc[i].question\n",
    "    print(f\"original_q: {original_q}\")\n",
    "    query = f\"What is {subject}\"\n",
    "    print(f\"query: '{subject}'\")\n",
    "    resp = vectorstore.similarity_search(query, k=1000)\n",
    "    for doc in resp:\n",
    "        title_ = rag_wikipedia.clean_title(doc.metadata['title'])\n",
    "\n",
    "        if title_ in top_1k_topics:\n",
    "            print(\n",
    "                f\"\\tdoc: {doc.metadata['title']}; url - {doc.metadata['url']}\")\n",
    "            views = top_1k_topics[title_]\n",
    "            print(f\"\\t\\tviews: {views}\")\n",
    "    print(\"\\n\")\n",
    "    if i > 5:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
